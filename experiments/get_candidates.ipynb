{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import os\n",
    "import pickle\n",
    "from datasketch import MinHash, MinHashLSHForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    text=re.sub(r'[^\\w\\s]','',text)\n",
    "    tokens=text.lower()\n",
    "    tokens=re.split(r'[\\s_]',tokens)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_forest(data,perms):\n",
    "    start_time=time.time()\n",
    "    minhash=[]\n",
    "    \n",
    "    m=MinHash(num_perm=perms)\n",
    "    for entity in data:\n",
    "        tokens=preprocess(entity)\n",
    "        m=MinHash(num_perm=perms)\n",
    "        for s in tokens:\n",
    "            m.update(s.encode('utf8'))\n",
    "        minhash.append(m)    \n",
    "    \n",
    "    forest=MinHashLSHForest(num_perm=perms)\n",
    "    for i,m in enumerate(minhash):\n",
    "        forest.add(i,m)\n",
    "    \n",
    "    forest.index()\n",
    "    print('It took {} seconds to build forest.'.format(time.time()-start_time))\n",
    "    return forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(query_entity,entities,perms,num_results,forest):    \n",
    "    tokens=preprocess(query_entity)\n",
    "    m=MinHash(num_perm=perms)\n",
    "    for s in tokens:\n",
    "        m.update(s.encode('utf8'))\n",
    "    \n",
    "    idx_array=np.array(forest.query(m,num_results))\n",
    "    if len(idx_array)==0:\n",
    "        return None\n",
    "    \n",
    "    results=[]\n",
    "    for idx in idx_array: results.append(entities[idx])\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='D:/Projects/DH/Intern/VinAI/Repos/secret/dataset/KDWD'\n",
    "file='training_data//entity2id.txt'\n",
    "entities=[]\n",
    "with open(os.path.join(folder,file),'r',encoding='utf8') as f:\n",
    "    lines=f.readlines()\n",
    "    for line in lines[1:]:\n",
    "        ent,id=line.strip().split('\\t')\n",
    "        entities.append(ent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It took 200.7253224849701 seconds to build forest.\n",
      "Wall time: 3min 20s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "permutations=128\n",
    "forest=get_forest(entities,permutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickleOut=open('D:/Projects/DH/Intern/VinAI/Repos/secret/models/weights/lsh_forest.pkl','wb')\n",
    "pickle.dump(forest,pickleOut)\n",
    "pickleOut.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lionel_messi']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_entity='messi'\n",
    "num_results=5\n",
    "predict(query_entity,entities,permutations,num_results,forest)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
